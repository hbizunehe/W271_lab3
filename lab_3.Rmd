---
title: 'Lab 3: Panel Models'
subtitle: 'US Traffic Fatalities: 1980 - 2004'
output: 
  bookdown::pdf_document2: default
---

```{r load packages, echo=FALSE, message=FALSE}

library(plm)
library(grid)
library(ggrepel)
library(gridExtra)
library(tidyverse)
library(patchwork)
```

# U.S. traffic fatalities: 1980-2004

In this lab, we are asking you to answer the following **causal** question: 

> **"Do changes in traffic laws affect traffic fatalities?"**  

To answer this question, please complete the tasks specified below using the data provided in `data/driving.Rdata`. This data includes 25 years of data that cover changes in various state drunk driving, seat belt, and speed limit laws. 

Specifically, this data set contains data for the 48 continental U.S. states from 1980 through 2004. Various driving laws are indicated in the data set, such as the alcohol level at which drivers are considered legally intoxicated. There are also indicators for “per se” laws—where licenses can be revoked without a trial—and seat belt laws. A few economics and demographic variables are also included. The description of the each of the variables in the dataset is also provided in the dataset. 

```{r load data, echo = TRUE}
load(file="./data/driving.RData")

## please comment these calls in your work 
#glimpse(data)
#desc
```


# (30 points, total) Build and Describe the Data 

```{r echo=FALSE}
# 1. (5 points) Load the data and produce useful features. Specifically: 
#     - Produce a new variable, called `speed_limit` that re-encodes the data that is in `sl55`, `sl65`, `sl70`, `sl75`, and `slnone`; 
#     - Produce a new variable, called `year_of_observation` that re-encodes the data that is in `d80`, `d81`, ... , `d04`. 
#     - Produce a new variable for each of the other variables that are one-hot encoded (i.e. `bac*` variable series). 
#     - Rename these variables to sensible names that are legible to a reader of your analysis. For example, the dependent variable as provided is called, `totfatrte`. Pick something more sensible, like, `total_fatalities_rate`. There are few enough of these variables to change, that you should change them for all the variables in the data. (You will thank yourself later.)
# 2. (5 points) Provide a description of the basic structure of the dataset. What is this data? How, where, and when is it collected? Is the data generated through a survey or some other method? Is the data that is presented a sample from the population, or is it a *census* that represents the entire population? Minimally, this should include:
#     - How is the our dependent variable of interest `total_fatalities_rate` defined? 
# 3. (20 points) Conduct a very thorough EDA, which should include both graphical and tabular techniques, on the dataset, including both the dependent variable `total_fatalities_rate` and the potential explanatory variables. Minimally, this should include: 
#     - How is the our dependent variable of interest `total_fatalities_rate` defined? 
#     - What is the average of `total_fatalities_rate` in each of the years in the time period covered in this dataset? 
# 
# As with every EDA this semester, the goal of this EDA is not to document your own process of discovery -- save that for an exploration notebook -- but instead it is to bring a reader that is new to the data to a full understanding of the important features of your data as quickly as possible. In order to do this, your EDA should include a detailed, orderly narrative description of what you want your reader to know. Do not include any output -- tables, plots, or statistics -- that you do not intend to write about.
```

```{r reencode}
# For the fractions, we are taking the majority as a speed limit
# We skipped year_of_observation since there a year column which aligns with dx
df <- data %>%
  mutate(speed_limit = ifelse(sl55 >= 0.5, '55',
                       ifelse(sl65 >= 0.5, '65',
                       ifelse(sl70 >= 0.5, '70',
                       ifelse(sl75 >= 0.5, '75',
                       ifelse(slnone >= 0.5, 'none', '0')
                       ))))) %>%
           mutate(speed_limit=factor(speed_limit, 
                  levels=c('55', '65', '70', '75', 'none')),
         blood_alcohol_limit_10 = ifelse(bac10 >= 0.5, 1, 0),
         blood_alcohol_limit_08 = ifelse(bac08 >= 0.5, 1, 0)) %>% 
  mutate(bac=ifelse(blood_alcohol_limit_10==1, '10', 
             ifelse(blood_alcohol_limit_08==1, '8', 'none'))) %>%
  mutate(bac=factor(bac, levels=c('none', '10', '8'))) %>%
  select(!c((sl55:slnone), (d80:d04), bac10, bac08)) %>% # Excluding
  rename(minimum_drinking_age = minage, zero_tolerance_law = zerotol,
         graduated_drivers_license_law = gdl, per_se_law = perse,
         total_fatalities = totfat, nighttime_fatalities = nghtfat,
         weekend_fatalities = wkndfat, total_fatalities_per_100M_miles = totfatpvm,
         nighttime_fatalities_per_100M_miles = nghtfatpvm,
         weekend_fatalities_per_100M_miles = wkndfatpvm,
         state_population =  statepop, total_fatalities_rate = totfatrte,
         nighttime_fatalities_rate = nghtfatrte,
         weekend_fatalities_rate = wkndfatrte,
         vehicle_miles_traveled = vehicmiles, unemployment_rate = unem,
         population_aged_14_to_24_rate = perc14_24,
         speed_limit_70_plus = sl70plus, 
         seat_belt = seatbelt,
         primary_seatbelt_law = sbprim, secondary_seatbelt_law = sbsecon,
         miles_driven_per_capita = vehicmilespc) %>%
  mutate(speed_limit_70_plus = 
           ifelse(speed_limit_70_plus>0.5, 1, 0)
           ) %>%
  mutate(seat_belt_law = 
           ifelse(seat_belt==0, 'none',
           ifelse(seat_belt==2, 'secondary', 
           ifelse(seat_belt==1, 'primary', 'na')))) %>%
  mutate(seat_belt_law=factor(seat_belt_law, 
                              levels=c('none', 'secondary', 'primary')),
         ) %>%
  mutate(per_se_law=round(per_se_law, 0)) %>%
  mutate(per_se_law=factor(per_se_law, levels=c(0, 1)))
  

# Adding states to the dataframe
state_df <- data.frame("index" = 1:51,
                       "state_name" = sort(c(state.name, "District of Columbia")))
main_df <- merge(df, state_df, by.x = 'state', by.y ='index')

pdata <- pdata.frame(main_df, index=c("state", "year"))
head(main_df)
```

```{r eda plots, fig.height=7}

# Time series line plot
# Variable to plot as var_name
# Each line gets a color based on the group_name
# X-axis is always year
plots.ts.by.group <- function(df, var_name, group_name, subtitle='') {
plt <- df %>% 
  mutate(!!group_name := factor(df[[group_name]])) %>% 
    ggplot(aes_string(x='year', y=var_name, group='state')) + 
    geom_line(aes_string(color=group_name)) +
  labs(subtitle=subtitle) +
  theme(legend.position = c(0.8, 0.8), legend.key.size = unit(0.2, "cm"), 
        legend.text=element_text(size=rel(0.5)), 
        legend.title=element_text(size=rel(0.7)))
  return((plt))
}


# Box plot by group
# Variable to plot as var_name
# Each group is plit by group_name
plots.box.by.group <- function(df, var_name, group_name, subtitle='') 
  {
plt <- df %>% mutate(factored=factor(df[[group_name]])) %>% 
    ggplot(aes_string(x='factored', y=var_name)) + 
     geom_boxplot(outlier.colour="red", outlier.shape=8,  outlier.size=4) +
  theme(axis.text.x=element_text(angle=-90)) +
  labs(subtitle=subtitle) +
  xlab(group_name)
  return((plt))
}


# Time series line plot
# Variable to plot as var_name
# Each line gets a color based on the group_name
# X-axis is always year
plots.scatter.by.state <- function(df, var_name, subtitle='') {
plt <- df %>% 
    ggplot(aes_string(x=var_name, y='total_fatalities_rate', group='state')) +
    theme(axis.text.x=element_text(angle=-90)) + 
    geom_point(aes_string(color='state_name')) +
  labs(subtitle=subtitle) +
  theme(legend.position = 'none')
  return((plt))
}

```

## Main Plots

```{r overall mean EDA, echo=FALSE}
# Average mean for total_fatalities_rate over years
main_plt <- main_df %>%
  group_by(year) %>%
  summarise(mean = mean(total_fatalities_rate), n = n()) %>%
  ggplot(aes(x = year, y = mean)) +
  geom_line() +
  labs(title = "Average mean fatality rate across US",
       subtitle = "Fatality rate is going down",
       x = "Year",  y = "Fatality Rate") +
  theme(legend.position = "none")

main_plt
```
\newpage
```{r, fig.width=8, fig.height=11, echo=FALSE}

# Speed limit
plt.ts.sl = plots.ts.by.group(
  main_df, 'total_fatalities_rate', 'speed_limit',
  subtitle='Traffic fatalities in state colored by speed limit')

tmp_df <- main_df %>% filter(year>1987)
plt.box.sl = plots.box.by.group(
  tmp_df, 'total_fatalities_rate', 'speed_limit',
  subtitle='Fatalities comparison for year > 1987')

# Speed limit
plt.ts.sl70p = plots.ts.by.group(
  main_df, 'total_fatalities_rate', 'speed_limit_70_plus',
  subtitle='Traffic fatalities in state colored by speed limit > 70mph')

tmp_df <- main_df %>% filter(year>1995)
plt.box.sl70p = plots.box.by.group(
  tmp_df, 'total_fatalities_rate', 'speed_limit_70_plus',
  subtitle='Fatalities comparison for year > 1987')

# Seat belt law
plt.ts.sb = plots.ts.by.group(
  main_df, 'total_fatalities_rate', 'seat_belt_law',
  subtitle='Traffic fatalities in state colored by seat belt laws')

tmp_df <- main_df %>% filter(year>1987)
plt.box.sb = plots.box.by.group(
  tmp_df, 'total_fatalities_rate', 'seat_belt_law',
  subtitle='Fatalities comparison for year > 1987')

# Graduated drivers licence law
tmp_df <- main_df %>% mutate(
  graduated_drivers_license_law=round(graduated_drivers_license_law, 0))
plt.ts.gdl = plots.ts.by.group(tmp_df, 
  'total_fatalities_rate', 'graduated_drivers_license_law',
  subtitle='Traffic fatalities in state colored by graduated drivers licence laws')

tmp_df <- tmp_df %>% filter(year>1995)
plt.box.gdl = plots.box.by.group(
  tmp_df, 'total_fatalities_rate', 'graduated_drivers_license_law',
  subtitle='Fatalities comparison for year > 1995')

# Per-Se law
tmp_df <- main_df
plt.ts.ps = plots.ts.by.group(tmp_df, 
  'total_fatalities_rate', 'per_se_law',
  subtitle='Traffic fatalities in state colored by Per-se law')

tmp_df <- tmp_df %>% filter(year>1990)
plt.box.ps = plots.box.by.group(
  tmp_df, 'total_fatalities_rate', 'per_se_law',
  subtitle='Fatalities comparison for year > 1990')

# BAC levels
plt.ts.bac = plots.ts.by.group(
  main_df, 'total_fatalities_rate', 'bac',
  subtitle='Traffic fatalities in state colored by BAC level')
plt.box.bac = plots.box.by.group(
  main_df %>% filter(year>1990), 'total_fatalities_rate', 'bac',
  subtitle='Fatalities comparison for year > 1990')


(plt.ts.sl | plt.box.sl)/(plt.ts.sl70p | plt.box.sl70p)/
 (plt.ts.sb | plt.box.sb)/(plt.ts.gdl | plt.box.gdl)/
  (plt.ts.ps | plt.box.ps) /(plt.ts.bac | plt.box.bac)
```

### Description of factor independent variables

> The highway speed limit was uniformly 55mph across all states before 1987. Since then, different states have adopted different speed limits. Especially in 1997, there was a signifcant increase in highway speeds across multiple states.The box plot compares the fatality rate across different speed limits  filtered for years greater than 1987. We see that increasing speed limits are associated with increased fatality rates. As there are states with no speed limit, this variables has been treated as a factor. 

> Now thresholding speed limits for greater or lower than 70mph shows a similar pattern of higher speeds associated with a higher fatality rate.

> Seat belts started to become mandatory starting mid to late 80s and today there is only one state which does not have it as mandatory. Primary laws are the strictest and allow police to ticket drivers and passengers who are not wearing a proper safety restraint, even if that is the only traffic violation they are committing. Secondary seat belt laws, on the other hand, do not grant law enforcement officials the right to ticket drivers or passengers for failing to wear a safety restraint unless another traffic violation has occurred. There are 15 states with secondary seat belt laws. Source: https://www.cooper-law-firm.com/what-is-the-difference-between-primary-and-secondary-seat-belt-laws/. 

> The graduated drivers licence law was started to be introduced in the late 90's. The box plot, which has been filtered for years greater than 1995, suggests that even for that time frame, there is a reduction in fatality rate between the two groups.

> Some states had Per-Se laws before the start of the data in 1980 and some still did not have Per-Se laws in 2004. There is a gradual increase in the adoption of the law from 1980 to about the 2000s. Surorisingly, there is an increase in fatality rates in comparison of data with PerSe law as compared to without. 

> BAC level

### Description of continous variables

```{r, fig.width=8, fig.height=9, echo=FALSE}

# population_aged_14_to_24_rate
tmp_df <- main_df %>% mutate(population_aged_14_to_24_rate=
                               round(population_aged_14_to_24_rate/3, 0) *3)
plt.ts.perc = plots.ts.by.group(
  tmp_df, 'total_fatalities_rate', 'population_aged_14_to_24_rate',
  subtitle='Traffic fatalities in state colored by population 14 to 24 age rate')

tmp_df <- main_df %>% filter(year>1980)
plt.scatter.perc = plots.scatter.by.state(
  tmp_df, 'population_aged_14_to_24_rate',
  subtitle='population aged 14 to 24_rate relationship to fatality rate')

# Miles driven per capita
tmp_df <- main_df %>% mutate(miles_driven_per_capita=
                               round(miles_driven_per_capita/2000, 0)*2000)
plt.ts.mpc = plots.ts.by.group(
  tmp_df, 'total_fatalities_rate', 'miles_driven_per_capita',
  subtitle='Traffic fatalities in state colored by miles_driven_per_capita')

plt.scatter.mpc = plots.scatter.by.state(
  tmp_df, 'miles_driven_per_capita',
  subtitle='miles driven per capita relationship to fatality rate')

# Unemployment rate
tmp_df <- main_df %>% mutate(unemployment_rate=round(unemployment_rate/3, 0)*3)

plt.ts.ur = plots.ts.by.group(
  tmp_df, 'total_fatalities_rate', 'unemployment_rate',
  subtitle='Traffic fatalities in state colored by unemployment rate')

plt.scatter.ur = plots.scatter.by.state(
  tmp_df, 'unemployment_rate',
  subtitle='unemployment rate relationship to fatality rate')

# Minimum drinking age
tmp_df <- main_df %>% mutate(minimum_drinking_age=round(minimum_drinking_age, 0))
plt.ts.mda = plots.ts.by.group(
  tmp_df, 'total_fatalities_rate', 'minimum_drinking_age',
  subtitle='Traffic fatalities in state colored by minimum drinking age')

plt.scatter.mda = plots.scatter.by.state(
  main_df, 'minimum_drinking_age',
  subtitle='Minimum drinking age relationship to fatality rate')


(plt.ts.perc | plt.scatter.perc) /  (plt.ts.mpc | plt.scatter.mpc) /
  (plt.ts.ur | plt.scatter.ur) / (plt.ts.mda | plt.scatter.mda)
```

> There is a decrease in the percetage of 14 to 24 year olds in the population over time. This is correlated to the decrease in the fatalities during that time period.



```{r, fatality rate by state EDA, fig.height=6, fig.width=12}
cut_point <- c(-1, 12, 24, 36, 48)
plots <- vector('list', 4)

for (i in 2:5) {
  plots[[i-1]] <- (pdata %>%
    filter(as.integer(state) > cut_point[i-1] & as.integer(state) <= cut_point[i]) %>%
    ggplot(aes(x = as.Date(year,"%Y"), y = total_fatalities_rate)) +
    geom_line() +
    facet_wrap(~ state_name, nrow = 3, ncol=4) +
    labs(x = "Year",  y = "Total Fatalities Rate") +
    theme(legend.position = "none"))
}

grid.arrange(plots[[1]], plots[[2]], plots[[3]], plots[[4]], nrow = 2, ncol = 2,
             top = textGrob("Fatality rate by states", gp=gpar(fontsize=20)))
```
> 'For most states, fatality rates go down over the years, but some states like Alabama and Arkansas do not show many changes. Surprisingly, Mississippi has an increase in the fatality rate.'  

```{r EDA TODO}
# traffic laws that we are exploring are seat_belt, minimum_drinking_age,
# zero_tolerance_law, graduated_drivers_license_law, per_se_law, speed_limit, 
# speed_limit_70_plus, primary_seatbelt_law, secondary_seatbelt_law, 
# blood_alcohol_limit_10, blood_alcohol_limit_08
```

# (15 points) Preliminary Model

Estimate a linear regression model of *totfatrte* on a set of dummy variables for the years 1981 through 2004 and interpret what you observe. In this section, you should address the following tasks: 

- Why is fitting a linear model a sensible starting place? 
- What does this model explain, and what do you find in this model? 
- Did driving become safer over this period? Please provide a detailed explanation.
- What, if any, are the limitation of this model. In answering this, please consider **at least**: 
    - Are the parameter estimates reliable, unbiased estimates of the truth? Or, are they biased due to the way that the data is structured?
    - Are the uncertainty estimate reliable, unbiased estimates of sampling based variability? Or, are they biased due to the way that the data is structured? 

```{r}
pooled_ols <- plm(total_fatalities_rate ~ year, data = pdata,
                  index = c("state", "year"),
                  effect = "individual", model = "pooling")
summary(pooled_ols)
```

> 'Starting from a linear model will give us an easy and intuitively clearer overall pattern over the years via the coefficients on the year dummy variables (or instead by adding group ids as dummy variables) using controlling for any variable of interest, if any. Later on, when we perform panel data analysis, we can compare it against the linear model, justify the result and keep building the intuition on top of the linear model.'  

> 'This model explains the fatality rate over different years compared to the baseline year, which is 1980. All coefficients except for the 1981 year are statistically significant. From this model, we learn that in all years following the baseline up to 2004, the fatality rate goes down compared to the baseline year 1980. The decline increases as the year increases but not consistently, as seen, for example, between 1986 - 1988, where the fatality rate increases compared to previous years. However, it returns to the decline track/trend in 1989. The decrease in coefficients over the years means that driving becomes safer as the fatality rate keeps decreasing. For example, the fatality rate, which was 25.5 as of 1980, became 19.5 in 1990, 16.8 in 2000, and 16.7 in 2004, showing that driving over the years has become safer. In other words, around 8.8 fewer people are predicted to get traffic fatalities out of 100,000 people in 2004 than in 1980.'   

> 'We are ignoring unobserved Heterogeneity and the group structure by taking each entry as a separate observation. Because of that, residuals generally correlate across time and have heteroskedasticity across and/or within groups. Heteroscedastic residuals are a violation of the OLS Homoscedasticity assumption, which will make it difficult to trust the standard error. As a result, the confidence interval can not be trusted as it can be too wide or narrow. Also, the independence assumption (no autocorrelation) is violated since we did not accommodate the lag/trend component, which makes the OLS estimates to be unreliable; in other words, our OLS estimator is not the Best Linear Unbiased Estimator.'   

# (15 points) Expanded Model 

Expand the **Preliminary Model** by adding variables related to the following concepts: 

- Blood alcohol levels 
- Per se laws
- Primary seat belt laws (Note that if a law was enacted sometime within a year the fraction of the year is recorded in place of the zero-one indicator.)
- Secondary seat belt laws 
- Speed limits faster than 70 
- Graduated drivers licenses 
- Percent of the population between 14 and 24 years old
- Unemployment rate
- Vehicle miles driven per capita. 

If it is appropriate, include transformations of these variables. Please carefully explain carefully your rationale, which should be based on your EDA, behind any transformation you made. If no transformation is made, explain why transformation is not needed. 

- How are the blood alcohol variables defined? Interpret the coefficients that you estimate for this concept. 
- Do *per se laws* have a negative effect on the fatality rate? 
- Does having a primary seat belt law? 

```{r expanded model}
expanded.ols.data <- main_df %>% select(c(total_fatalities_rate, bac, per_se_law, 
                   seat_belt_law, graduated_drivers_license_law,
                   population_aged_14_to_24_rate, minimum_drinking_age,
                   unemployment_rate, speed_limit_70_plus, 
                   miles_driven_per_capita, year, state_name
                   )) 

# expanded.ols <- lm(
#   total_fatalities_rate ~  factor(year) + bac + population_aged_14_to_24_rate + 
#     miles_driven_per_capita + unemployment_rate +
#     speed_limit_70_plus +
#     per_se_law + seat_belt_law + graduated_drivers_license_law, 
#   data = expanded.ols.data)

main_p <- pdata.frame(main_df, index=c("state", "year"))

expanded.ols <- plm(total_fatalities_rate ~  state + bac + 
                      population_aged_14_to_24_rate + miles_driven_per_capita + 
                      unemployment_rate + speed_limit_70_plus + per_se_law + 
                      seat_belt_law + graduated_drivers_license_law,
                    data = main_p,
                  index = c("state", "year"),
                  effect = "individual", model = "pooling")
summary(expanded.ols)

```

# (15 points) State-Level Fixed Effects 

Re-estimate the **Expanded Model** using fixed effects at the state level. 

- What do you estimate for coefficients on the blood alcohol variables? How do the coefficients on the blood alcohol variables change, if at all? 
- What do you estimate for coefficients on per se laws? How do the coefficients on per se laws change, if at all? 
- What do you estimate for coefficients on primary seat-belt laws? How do the coefficients on primary seatbelt laws change, if at all? 

Which set of estimates do you think is more reliable? Why do you think this? 

- What assumptions are needed in each of these models?  
- Are these assumptions reasonable in the current context?

# (10 points) Consider a Random Effects Model 

Instead of estimating a fixed effects model, should you have estimated a random effects model?

- Please state the assumptions of a random effects model, and evaluate whether these assumptions are met in the data. 
- If the assumptions are, in fact, met in the data, then estimate a random effects model and interpret the coefficients of this model. Comment on how, if at all, the estimates from this model have changed compared to the fixed effects model. 
- If the assumptions are **not** met, then do not estimate the data. But, also comment on what the consequences would be if you were to *inappropriately* estimate a random effects model. Would your coefficient estimates be biased or not? Would your standard error estimates be biased or not? Or, would there be some other problem that might arise?

# (10 points) Model Forecasts 

The COVID-19 pandemic dramatically changed patterns of driving. Find data (and include this data in your analysis, here) that includes some measure of vehicle miles driven in the US. Your data should at least cover the period from January 2018 to as current as possible. With this data, produce the following statements: 

- Comparing monthly miles driven in 2018 to the same months during the pandemic: 
  - What month demonstrated the largest decrease in driving? How much, in percentage terms, lower was this driving? 
  - What month demonstrated the largest increase in driving? How much, in percentage terms, higher was this driving? 
  
Now, use these changes in driving to make forecasts from your models. 

- Suppose that the number of miles driven per capita, increased by as much as the COVID boom. Using the FE estimates, what would the consequences be on the number of traffic fatalities? Please interpret the estimate.
- Suppose that the number of miles driven per capita, decreased by as much as the COVID bust. Using the FE estimates, what would the consequences be on the number of traffic fatalities? Please interpret the estimate.

# (5 points) Evaluate Error 

If there were serial correlation or heteroskedasticity in the idiosyncratic errors of the model, what would be the consequences on the estimators and their standard errors? Is there any serial correlation or heteroskedasticity? 